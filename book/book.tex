% \documentclass{article}
\documentclass[letterpaper,11pt]{article}
\usepackage[margin=1in,footskip=0.25in]{geometry}

\usepackage[parfill]{parskip} % this makes paragraph indentation consistent
\usepackage{amsthm, amssymb, amsmath} % math packages
\usepackage{hyperref}
\usepackage{graphicx} % Required for inserting images
\usepackage[T1]{fontenc}
\usepackage{palatino}
\usepackage{courier}
\usepackage{listings}
\usepackage{xcolor}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

\lstset{style=mystyle}

\title{Building a Chess Engine}
\author{Jerome Wei}
\date{2024}

\begin{document}

\maketitle
\newpage
\tableofcontents

\newpage
\part{Introduction}

Wherever computing goes, chess programming goes too.

From the original Mechanical Turk to Deep Blue to Stockfish NNUE, chess programs have been a fascination in popular culture as well as nerd culture.

It's a rewarding way for the growing programmer to cut their teeth. Chess programming is a multidisciplinary field. Of course, the crux is programming and theoretical computer science, but along the way we visit hardware engineering, mathematics, statistics, and data science.

One of the first personal projects I ever did was a chess engine in Python. This was back in middle school, when I had no idea what Big O meant, nor did I have any idea about Git, or DevOps pipelines, or code reviews. It was a time of programming anarchy in my life, where feedback from others was rare and freedom was unlimited. The feeling of figuring out an algorithm for knight movement, for example, was one of the few times I felt like I "solved" a problem in programming entirely by myself (even though my solution was woefully slow).

Programming lala-land gets ruined once you get exposed to the real world, where freedom to solve problems is curtailed by operational requirements and a culture of pulling dependencies to solve problems. This sounds fine on paper, but ironically, comes into contact with reality when the problem of maintaining a project's dependency tree becomes a difficult problem itself. Now you have at least two problems. Working in "tech", you feel a distinct lack of freedom in your day-to-day work.

I think I've been chasing this feeling of freedom ever since.

\section{Roadmap}

We will be writing a chesse engine in C. This project will be split into three parts, beginner, intermediate, and advanced.

You might ask why we are using a low level language if this is a learning book. To that I would have two responses. 
One, I would look to my above rant and note that I want to fight against the culture of downloading someone else's solution to a problem. Sure, we could download a Python package and call it a day. But where's the fun in that? Second, I would respond by asking, "What's the purpose of a chess engine?" The answer is "Win". And to win in chess, you need to out-calculate your opponent. Thus performance seriously matters in a chess engine.

I haven't measured, but would guess that the performance of Java or Rust (or one of the many new C alternatives) 
would be acceptable for a strong chess engine. I chose C over one of those languages mainly due to (possibly marginal) 
performance advantage and compiler maturity (GCC is far older than I am, Clang/LLVM is an awesome project, and MSVC... exists). 
C is also accepted in the computer chess community (although C++ is seemingly more popular there).

For this project, we assume you have experience with C.
We are forgoing C++ for several reasons:

\begin{itemize}
\item C++ standard library data structures like std::vector are not tuned for chess programming.
\item The heap allocations needed for a chess engine aren’t so complicated that we need C++ smart pointers.
\item Memory safety is not much of a concern with a chess engine, so we can manually do heap allocations without fear.
\item Constructors/destructor pairings are annoying together with custom allocators (i.e. an arena, if we do decide to use one).
\item This might be controversial: performance is harder to reason with in C++. This has to do with hidden control flow and the language having more options to make things complicated, such as lambdas.
\item It's always possible to go from C to C++, if we really require a certain feature. The other direction is not possible.
\item Working in C++ tends to be so difficult that you end up having to restrict yourself to a subset of the language. C is right there...
\end{itemize}
This does give us some drawbacks:
\begin{itemize}
\item No methods: we’ll never be able to do x.thing(), so our function names will be longer
\item In a similar vein, no namespaces.
\item No references: we will be dealing in raw pointers or values.
\item No generics (i.e. iterator abstraction).
\item Unsafe typing makes it easier to write severe bugs.
\item No OS abstractions (i.e. threads, filesystem)
\item Because of this, multi-core will be harder, due to lack of cross-platform thread syncronization primitives.
Expect there to be some conditional compilation flags and preprocessor macros.
\item No compile-time code.
\item Security. I guess it’s possible that if we have a buffer overflow vulnerability and expose the engine on the internet, maybe an attacker can hijack our server to mine bitcoin.
\end{itemize}

Yes, it is my opinion that object-oriented programming is bad, when defined as 
``No free functions and no global variables, everything must be in a class and there is an inheritance hierarchy``.
Looser definitions I'm OK with---of course, 
named struct types and fields are an essential part of any imperative language. 

I use CMake, which is a tool to generate build files for all of the major platforms/compilers. 
Kind of like a build-system-build-system. This isn't too important; if you prefer Makefiles or 
using Visual Studio natively everything should work fine. 
My preferred setup for writing C is CLion+Linux, though macOS works fine as well. 

\newpage
\part{Modeling Chess}

At the end of this part, you will have a working chess engine that sits around 1800-2000 ELO. 

\section{Project Setup}

Let's set up the environment.

\section{Game State}

Let's make a struct to represent a board position.

\subsection{Bitboards}

It can be difficult to wrap your head around bitboards at first. Let's begin by having a glance at 
how set operations map onto bitwise operators.

\subsection{Bit Twiddling}
\subsection{Parsing FEN}
\subsection{Exercises}

\section{Move Generation}

In this section, we generate possible moves given a position.

\subsection{Making and Unmaking}
\subsection{Captures}
\subsection{Castling}
\subsection{En Passant}
\subsection{Promotions}
\subsection{Move Stack}
\subsection{Exercises}

\section{Testing}

Let's test and benchmark our move generation.

\subsection{Perft}
\subsection{Benchmarking}
\subsection{Exercises}

\part{A Minimal Engine}

\section{Static Evaluation}

Human chess players have to end their calculations somewhere. Usually they do in a position 
that they can evaluate, that is, assess without calculating any more moves.

This is kind of a strange activity since no tactics or moves are assessed; you're only 
evaluating the features of a position such as the material. This might jump out at you as 
slightly stupid; if it does, peek forward to the chapter about Quiescence search.

The commonly accepted wisdom was that human chess players are
much better than computers at evaluating positions;
this changed around the mid 2010s as neural network evaluations started to become 
efficiently incorporable into engines. 

\subsection{Material}

Material is a clear evaluation feature.
\begin{lstlisting}[language=C]
f64 evaluate_material(Board *board, i32 color) {
  static const f64 material_table[8] = {0,     0,     100.0, 301.0,
                                        299.0, 500.0, 900.0, 0};
  f64 material = 0;
  for (int i = 2; i < 8; i++) {
    i32 count = pop_count(board->_bitboard[color] & board->_bitboard[i]);
    material += material_table[i] * count;
  }
  return material;
}
\end{lstlisting}
\subsection{King Safety}



\subsection{Pieces}
\subsection{Exercises}

\section{Search}

In this chapter we will begin implementing our game tree search. There is a tension between
search and evaluation: generally, the stronger the evaluation, the slower it is,
and the search will see fewer positions. A weaker, faster evaluation sees more positions.
Of course, this is a rule of thumb; you want a fast and strong evaluation function. 

\subsection{Minimax}
\subsection{Alpha-Beta}
\subsection{Iterative Deepening}
\subsection{Exercises}

\section{UCI Protocol}

Let's take a quick detour and get our engine communicating with the outside world.

\subsection{Parsing Input}
\subsection{Interrupting Search}
\subsection{Exercises}

\section{Strength Estimation}

In this chapter, we'll implement some important testing benchmarks, most importantly asking,
how good at chess are we?

\subsection{ELO Estimation}
\subsection{Puzzles}
\subsection{Exercises}

\section{Quiescence Search}


If you've been playing or watching the engine play so far, you might notice it blunders a lot. This is our first 
exposure to the eternal problem with depth-limited game tree search: the dreaded horizon effect.

\subsection{Horizon Effect}

\subsection{Exercises}

\section{Move Ordering}
Move ordering is critical to search performance.

This is going to be a short chapter, 
but note this is a cross-cutting concept that overlaps a lot with other chapters.
Many chapters ahead may touch our move ordering code. It's not an independent topic.
In a later chapter we will deep-dive on move ordering. Here we more or less only 
implement the skeleton.

\subsection{Move Scoring}
Our first try at scoring moves will be such: first, we try the best move from previous iterative 
deepening iteration, then we try promotions, then captures. This is an extremely simiplistic way of doing 
things.

\subsubsection*{To sort or not to sort}

Once we have our moves scored, it's important to ask how we're going to pop our
our highest scored move from the list. We could go ahead and sort ahead of time;
but remember, in alpha-beta search we're expecting a cut-off very early on in most nodes.

This means that sorting the entire move list ahead of time might be less efficient than 
doing a full-list scan. And looking ahead, we might generate moves in stages: i.e.,
first generate checks, then captures, then special moves, then non-captures. Here, a whole-list 
sort doesn't make a ton of sense.

The CS major in you might say use a priority queue. It's possible that this is a good
solution as well.

\subsubsection*{Looking ahead}

In the later move ordering chapter we will both add more criteria for our base move ordering, 
introduce some algorithms for scoring moves, and introduce some interesting heuristics for 
ordering moves.

\subsection{Exercises}

\subsubsection{}

How could we order captures better? Come up with an efficient algorithm for this.

\subsubsection{}

There is a chess adage, ``You must calculate checks, captures, and attacks``. 
Why or why not might this be good advice for a chess engine programmer? If it is, how would 
we efficiently implement it in our engine?

\section{Transposition Tables}

At this point, I ran 1000 games of the engine versus Stockfish set to an ELO limited to 1320. The results concluded that the engine's ELO is ~1200.

A couple major issues is that it falls for repetitions, and also does not distinguish between Mate-in-N. Furthermore, on short time controls (say 1 second per move) it often fails to find good moves, because it can't calculate deep enough in such a small time. These will both be covered in later chapters.

We would a way to place our board state into a hash table, in order to memoize previous search results. This should speed up our search at the expense of some space.
The process of doing so ends up being somewhat tricky, but will have more benefits than just optimization. For one, having a board state hashing function 
will allow us to do repetition checking easily, as well will see soon. Another reason is that it has synergy with iterative deepening search: on the next iteration, in theory the search picks up right where it left off!

\subsection{Zobrist Hashing}

Here's our hashing function.

\subsection{Testing Hash Function}

It's easy to write bugs related to hashing so let's figure out a way to test our hash function.

\subsection{Hash Table}

\subsection{Exercises}

\section{Additional Rules}

We are now on the final chapter of Part 1.

\subsection{Three-fold Repetition}

The three-fold rule has some noteriety in the chess world for its difficulty to enforce. This has 
to do with the slight nuances in rule statement between different chess federations.
Basically, the confusion boils down to whether castling counts as an irreversible move or not.

A new piece of terminology shared between both repetition and 50 move draws: an irreversible move is one that must lead to a new position, and functionally,
our halfmove clock is incremented after every non-irreversible move. The irreversible moves are 
captures, pawn moves (because pawns can't move backwards), and castling.

For simplicity, we will treat any repeated position as a draw. There might be some advantage 
to having the option to repeat once, maybe to gain time on the clock.

Our algorithm is straightforward: search the last N positions for the same hash, where N is the number of positions since the last
irreversible move.

We implement it in a pretty slow manner
\subsection{50 Move Rule}
\subsection{Exercises}

\subsubsection{}
Can you think of a faster way to check for repeated position?


\section{Engine Reporting and Options}

In this chapter we complete our compliance of the UCI standard.

\subsection{Mate-in-N}

Here, we can kill two birds with one stone: 1) we can report out mate-in-N to the user, and 2) we can
distinguish in our search between distance to mate.

At a leaf node which is mate, we want to output a mating score, which should be higher
the closer the mate is.

\subsection{Recovering Principal Variation}

\subsection{Engine Options}

\subsection{Exercises}

\newpage
\part{Engine Optimization}

\section{Advanced Move Ordering Heuristics}

This is an extremely important chapter.
Move ordering is key achieving a lot of cutoffs in alpha-beta pruning. 
However, the implementation and concepts needed to perform
excellent move ordering are more in line with this section than the previous.

\subsection{Static Exchange Evaluation}
\subsection{Killer Move}
\subsection{Exercises}


\section{Tuned Evaluation}

This is our first foray into the world of statistics and applied statistics (also known as machine learning).

\section{Search Enhancements}

This chapter like, move ordering, is also fundamental to chess programming. With these strategies, 
we can begin to search to much higher depths like Stockfish does.

\subsection{Check Extensions}
\subsection{Null Move Pruning}
\subsection{Principal Variation Search}
\subsection{Aspiration Windows}
\subsection{Reductions}
\subsection{Exercises}

\section{Micro Optimization}

This should hopefully be a fun chapter where we optimize our move generation to squeeze as much performance 
as possible out of modern processors.

\subsection{Magic Bitboards}
\subsection{SIMD}
\subsection{Exercises}

\section{Time Management}

This brief chapter deals with finding algorithms for time management based on different time control formats.

\subsection{Pondering}

Pondering is simply ``thinking on the opponent's turn``.

\section{Parallel Search}

In the final chapter capping off this section, we use take advantage of multi processor systems in order to 
search even more nodes per second.

\subsection{Lazy SMP}

\newpage
\part{Advanced Engine Concepts}

\section{Neural Network Evaluation}

\section{AlphaZero and Monte-Carlo Tree Search}

\newpage
\part{Appendix}
\section{Note on Optimization}

It is very, very easy to go wrong when doing fine-grained optimization.

I remember doing research in college where my task was to speed up an ancient C++ codebase. I realized too late that a ton of my results were fudged because I had a web browser open for some tests, slowing them down significantly. Simply timing a function, or adding up time spent in a function, can be funny business.

\subsection{Hot-spot Optimization}

One way of doing optimization is via hot-spot optimization. This basically means offloading running your program to another program that counts exactly how many times each function is called and how much time is spent in each function.

Here is a way to generate a call graph on Linux (must have vallgrind, gprof2dot, and dot):

\begin{verbatim}
valgrind --tool=callgrind ./path_to_executable
gprof2dot -f callgrind callgrind.out.XXXXX | dot -Tsvg -o output.svg
\end{verbatim}

\subsection{Reading Assembly}

It's possible to tell your compiler to output assembly, but there's an easier way.

\href{https://godbolt.org/}{Compiler Explorer} is an online tool that outputs assembly and helps you read it.

It's interesting to set an optimization level flag (e.g., -O3) and see what kind of optimizations the compiler can do 
for you.


\subsection{Profiling Cache Misses}

However, simply reading the assembly might not be enough, because instruction count is dwarfed by the cost of cache misses. 

Basically, your CPU reads data from memory (RAM), but doing so is slow, so there are several caches in hardware
that cache memory and allow it to be read faster. CPUs do math directly on registers, so those 
are the fastest, but there are only a handful of registers per CPU.

\begin{center}
\begin{tabular}{ |c|c| }
\hline
register & 4 instructions per cycle \\ 
\hline
L1       & 3 cycles (12 x register) \\
\hline
L2       & 12 cycles (4 x L1, 48 x register) \\
\hline
L3       & 38 cycles (3 x L2, 12 x L1, 144 x register) \\
\hline
DRAM     & 65 ns = 195 cycles on a 3 GHz CPU (5 x L3, 15 x L2, 60 x L1, 720 x register) \\
\hline
\end{tabular}
\end{center}
Source: \url{https://stackoverflow.com/a/29188516/19457287}

So cache misses are about half an order of magnitude at each level of miss. In other words, cache is the 
daddy of optimization.

Cachegrind

\subsection{Branch Predictor}

Another place you will find weirdness (i.e., unexplainable performance gain/loss) is the branch predictor. I am not an 
expert on CPU architecture, but here's my best explanation:

CPUs save time by trying to guess the result of branch operations (in other words, if statements). 
There is some magic algorithm built in the hardware, kind of like a Rock-Paper-Scissors AI, 
which tries to figure out patterns in your branches, so that it guesses correctly more often.

In other words, you want to organize the results of your if/else statements to be as 
predictable as possible.

See: \href{https://stackoverflow.com/questions/11227809/why-is-processing-a-sorted-array-faster-than-processing-an-unsorted-array}{StackOverflow post on branch prediction}

\section{Lichess Deployment}

\end{document}
