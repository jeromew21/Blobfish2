\documentclass{article}
\usepackage[legalpaper, margin=1.5in]{geometry}
\usepackage{graphicx} % Required for inserting images
\usepackage[T1]{fontenc}
\usepackage{palatino}

\title{Building a Chess Engine}
\author{Jerome Wei}
\date{2024}

\begin{document}

\maketitle
\newpage
\tableofcontents

\newpage
\part{Introduction}
Wherever computing goes, chess programming goes too.

From the original Mechanical Turk to Deep Blue to Stockfish NNUE, chess programs have been a fascination in popular culture as well as nerd culture.

It's a rewarding way for the growing programmer to cut their teeth. Chess programming is a multidisciplinary field. Of course, the crux is programming and theoretical computer science, but along the way we visit hardware engineering, mathematics, statistics, and data science.

One of the first personal projects I ever did was a chess engine in Python. This was back in middle school, when I had no idea what Big O meant, nor did I have any idea about Git, or DevOps pipelines, or code reviews. It was a time of programming anarchy in my life, where feedback from others was rare and freedom was unlimited. The feeling of figuring out an algorithm for knight movement, for example, was one of the few times I felt like I "solved" a problem in programming entirely by myself (even though my solution was woefully slow).

Programming lala-land gets ruined once you get exposed to the real world, where freedom to solve problems is curtailed by operational requirements and a culture of pulling dependencies to solve problems. This sounds fine on paper, but ironically, comes into contact with reality when the problem of maintaining a project's dependency tree becomes a difficult problem itself. Now you have at least two problems. Working in "tech", you feel a distinct lack of freedom in your day-to-day work.

I think I've been chasing this feeling of freedom ever since.

\section{Roadmap}

We will be writing a chesse engine in C. This project will be split into three parts, beginner, intermediate, and advanced.

You might ask why we are using a low level language if this is a learning book. To that I would have two responses. One, I would look to my above rant and note that I want to fight against the culture of downloading someone else's solution to a problem. Sure, we could download a Python package and call it a day. But where's the fun in that? Second, I would respond by asking, "What's the purpose of a chess engine?" The answer is "Win". And to win in chess, you need to out-calculate your opponent. Thus performance seriously matters in a chess engine.

I haven't measured, but would guess that the performance of Java or Rust (or one of the many new C alternatives) would be acceptable for a strong chess engine. I chose C over one of those languages mainly due to (possibly marginal) performance advantage and compiler maturity (GCC is far older than I am, Clang/LLVM is an awesome project, and MSVC... exists). C is also accepted in the computer chess community (although C++ is apparently more popular there).

For this project, we assume you have experience with C.
We are forgoing C++ for several reasons:

\begin{itemize}
\item C++ standard library data structures like std::vector are not tuned for chess programming.
\item The heap allocations needed for a chess engine aren’t so complicated that we need C++ smart pointers.
\item Memory safety is not much of a concern with a chess engine, so we can manually do heap allocations without fear.
\item Constructors/destructor pairings are annoying together with custom allocators (i.e. an arena, if we do decide to use one).
\item This might be controversial: performance is harder to reason with in C++. This has to do with hidden control flow and the language having more options to make things complicated, such as lambdas.
\item It's always possible to go from C to C++, if we really require a certain feature. The other direction is not possible.
\item Working in C++ tends to be so difficult that you end up having to restrict yourself to a subset of the language. C is right there...
\end{itemize}
This does give us some drawbacks:
\begin{itemize}
\item No methods: we’ll never be able to do x.thing(), so our function names will be longer
\item In a similar vein, no namespaces.
\item No references: we will be dealing in raw pointers or values.
\item No generics (i.e. iterator abstraction).
\item Unsafe typing makes it easier to write severe bugs.
\item No OS abstractions (i.e. threads, filesystem)
\item Because of this, multi-core will be harder, due to lack of cross-platform thread syncronization primitives.
Expect there to be some conditional compilation flags and preprocessor macros.
\item No compile-time code.
\item Security. I guess it’s possible that if we have a buffer overflow vulnerability and expose the engine on the internet, maybe an attacker can hijack our server to mine bitcoin.
\end{itemize}
Yes, it is my opinion that object-oriented programming is bad, when defined as "No free functions and no global variables, everything must be in a class and there is an inheritance hierarchy". Looser definitions I'm OK with---of course, named struct types and fields are an essential part of any imperative language. 

I use CMake which is a tool to generates build files for all of the major platforms/compilers. Kind of like a build-system-build-system. This isn't too important; if you prefer Makefiles or using Visual Studio natively everything should work fine. My preferred setup for writing C is CLion+Linux, though macOS works fine as well. 

\newpage
\part{Beginner}
At the end of this part, you will have a working chess engine that sits around 1800-2000 ELO. 

\section{Project Setup}

\section{Game State}
\subsection{Bit Twiddling}
\subsection{Bitboards}
\subsection{Parsing FEN}
\subsection{Exercises}

\section{Move Generation}
\subsection{Making and Unmaking}
\subsection{Captures}
\subsection{Castling}
\subsection{En Passant}
\subsection{Promotions}
\subsection{Move Stack}
\subsection{Exercises}

\section{Testing}
\subsection{Perft}
\subsection{Benchmarking}
\subsection{Exercises}

\section{Evaluation}
\subsection{Material}
\subsection{King Safety}
\subsection{Pieces}
\subsection{Exercises}

\section{Search}
\subsection{Minimax}
\subsection{Alpha-Beta}
\subsection{Iterative Deepening}
\subsection{Exercises}

\section{UCI Protocol}
\subsection{Parsing Input}
\subsection{Interrupting Search}
\section{Exercises}

\section{Strength Estimation}
\subsection{ELO Estimation}
\subsection{Puzzles}
\subsection{Exercises}

\section{Quiescence Search}

\subsection{Horizon Effect}
At this point, I ran 1000 games of the engine versus Stockfish set to an ELO limited to 1320. The results concluded that the engine's ELO is ~1200.

A couple major issues is that it falls for repetitions, and also does not distinguish between Mate-in-N. Furthermore, on short time controls (say 1 second per move) it often fails to find good moves, because it can't calculate deep enough in such a small time. These will both be covered in later chapters.

\section{Transposition Tables}

We need a way to hash our current board state in order to index into a hash table. This should speed up our search at the expense of some space.
The process of doing so ends up being somewhat tricky, but will have more benefits than optimization--- it will allow us to do repetition checking easily, as well will see soon.

\subsection{Zobrist Hashing}
\subsection{Testing Hashing}
\subsection{Exercises}

\section{Additional Rules}
We are now on the final chapter of Part 1.
\subsection{Three-fold Repetition}
For simplicity, we will treat any repeated position as a draw.
Our algorithm is straightforward: search the last N positions for the same hash, where N is the number of positions since the last pawn move.
\subsection{50 Move Rule}
\subsection{Exercises}

\newpage
\part{Intermediate}
\section{Smarter Quiescence Search}
\subsection{Check Extensions}

\section{Engine Reporting}
\subsection{Mate-in-N}
\subsection{Recovering Principal Variation}
\subsection{Exercises}

\section{Engine Options}
\subsection{Hash Table Size}
\subsection{Exercises}
\section{Move Ordering Heuristics}
\subsection{Static Exchange Evaluation}
\subsection{Killer Move}
\subsection{Exercises}
\section{Fine Grained Optimization}
\subsection{Magic Bitboards}
\subsection{SIMD}
\subsection{Exercises}
\section{Tuned Evaluation}
\section{Search Enhancements}
\subsection{Null Move Pruning}
\subsection{Principal Variation Search}
\subsection{Aspiration Windows}
\subsection{Extensions}
\subsection{Reductions}
\subsection{Exercises}

\section{Parallel Search}
\subsection{Lazy SMP}

\newpage
\part{Advanced}

\section{Neural Network Evaluation}

\section{GPU Move Generation}

\section{AlphaZero and Monte-Carlo Tree Search}

\newpage
\part{Appendix}
\section{Note on Optimization}

It is very, very easy to go wrong when doing fine-grained optimization.

I remember doing research in college where my task was to speed up an ancient C++ codebase. I realized too late that a ton of my results were fudged because I had a web browser open for some tests, slowing them down significantly. Simply timing a function, or adding up time spent in a function, can be funny business.

\subsection{Hot-spot Optimization}

One way of doing optimization is via hot-spot optimization. This basically means offloading running your program to another program that counts exactly how many times each function is called and how much time is spent in each function.

Callgrind

\subsection{Reading Assembly}

It's possible to tell your compiler to output assembly, but there's an easier way.

Compiler Explorer


\subsection{Profiling Cache Misses}

However, simply reading the assembly might not be enough, because instruction count is dwarfed by the next optimization target.


According to this stackoverflow post https://stackoverflow.com/a/29188516/19457287

\begin{center}
\begin{tabular}{ |c|c| }
\hline
register & 4 instructions per cycle \\ 
\hline
L1       & 3 cycles (12 x register) \\
\hline
L2       & 12 cycles (4 x L1, 48 x register) \\
\hline
L3       & 38 cycles (3 x L2, 12 x L1, 144 x register) \\
\hline
DRAM     & 65 ns = 195 cycles on a 3 GHz CPU (5 x L3, 15 x L2, 60 x L1, 720 x register) \\
\hline
\end{tabular}
\end{center}


So cache misses are about half an order of magnitude at each level of miss. In other words, cache is the 
daddy of optimization.

Cachegrind

\subsection{Branch Predictor}

Another place you will find weirdness (i.e., unexplainable performance gain/loss) is the branch predictor.

\section{Lichess Deployment}

\end{document}
